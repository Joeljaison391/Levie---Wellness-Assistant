# Diary Annotation Submodule

## Overview
The Diary Annotation API is a FastAPI-based application that processes diary entries using natural language processing (NLP) techniques and an AI language model. It extracts entities, resolves relationships, and refines diary text with the help of both built-in NLP algorithms and an external AI model. The application integrates with a profile service and stores the processed results in a PostgreSQL database.

## Features
- **Diary Annotation:** Extracts entities (e.g., names and locations) and annotates relationships from diary text.
- **Coreference Resolution:** Utilizes spaCy to resolve pronouns and improve text clarity.
- **Relationship Graph Construction:** Uses NetworkX to build relationship graphs based on profile data.
- **Common Relation Mapping:** Detects common relation words (e.g., "Dad", "Mom") and maps them to canonical forms using a custom dictionary.
- **Writer Identification:** Extracts the writer's signature from the diary entry and uses fuzzy matching to determine if the diary is written by a child of the profile owner.
- **AI-Based Refinement:** Passes the diary entry and NLP annotations to an AI model (e.g., amethyst-13b-mistral) to produce a refined diary entry along with structured annotations.
- **Database Storage:** Saves the original diary text, the refined annotated text, structured annotations, and the full AI response in PostgreSQL.
- **API Endpoints:**
  - `/annotate/` — Process and store diary entries.
  - `/memory/{memory_id}` — Retrieve a single diary entry by ID.
  - `/memory/count` — Get the total number of diary entries.
  - `/stories/` — Fetch all stored diary entries.
- **CORS Support:** Configured to allow cross-origin requests from a wide range of local ports for development.

## Dependencies
- **FastAPI** – Web framework for building the API.
- **uvicorn** – ASGI server.
- **spaCy** – NLP library for tokenization and named entity recognition.
- **stanza** – Additional NLP processing.
- **SentenceTransformer** – For generating sentence embeddings.
- **NetworkX** – For building relationship graphs.
- **SQLAlchemy** – ORM for PostgreSQL integration.
- **httpx** – For asynchronous HTTP requests.
- **http.client** – For communicating with the AI model.
- **PostgreSQL** – Database for storing diary entries.

## Installation

1. **Clone the Repository:**
   ```bash
   git clone <repository-url>
   cd <repository-directory>
   ```

2. **Create and Activate a Virtual Environment:**
   ```bash
   python -m venv .venv
   source .venv/bin/activate   # On Windows: .venv\Scripts\activate
   ```

3. **Install Dependencies:**
   ```bash
   pip install -r requirements.txt
   ```
   *Ensure your `requirements.txt` includes packages such as FastAPI, uvicorn, spaCy, stanza, sentence-transformers, networkx, sqlalchemy, httpx, etc.*

4. **Download NLP Models:**
   - **spaCy:**
     ```bash
     python -m spacy download en_core_web_sm
     ```
   - **stanza:**
     ```bash
     python -c "import stanza; stanza.download('en')"
     ```

5. **Configure PostgreSQL:**
   - Ensure PostgreSQL is installed and running.
   - Update the `DATABASE_URL` in the code to match your PostgreSQL credentials.

6. **Set Up the AI Model:**
   - Configure the `LM_HOST` and `LM_PORT` in the code to point to your LM Studio (or another AI model server).

## Usage

- **Run the API Server:**
  ```bash
  uvicorn main:app --host 0.0.0.0 --port 6060
  ```
- **API Endpoints:**
  - POST `/annotate/` — Submit a diary entry for annotation.
  - GET `/memory/{memory_id}` — Retrieve a specific diary entry.
  - GET `/memory/count` — Get the total count of diary entries.
  - GET `/stories/` — Fetch all diary entries.

## Algorithms & Approach

1. **NLP Annotation:**
   - **Entity Extraction:** Uses spaCy and stanza to extract names and locations.
   - **Coreference Resolution:** Replaces pronouns with their respective noun references.
   - **Relationship Graph:** Constructs a relationship graph using NetworkX based on profile data.
   - **Fuzzy Matching:** Identifies the writer (extracted from the diary signature) and uses fuzzy matching to map common relation words (e.g., “Dad” to “father”) based on the profile’s family data.

2. **AI-Based Refinement:**
   - The refined diary entry and structured annotations are generated by passing the diary text along with the initial NLP annotations to an AI model.
   - The AI is instructed to return a structured JSON object containing:
     - `refined_text`: The refined diary entry.
     - `annotations`: A list of annotation objects (each with `entity`, `relationship`, and `context`).

3. **Database Storage:**
   - The API stores the original diary text, refined annotated text, structured annotations, and the full AI response in a PostgreSQL database.

## Additional Notes
- The application is designed for development purposes. In production, consider using a migration tool like Alembic to manage schema changes.
- The CORS middleware is configured to allow a broad range of local origins for testing purposes.

## Troubleshooting
- **Schema Issues:** If you encounter column errors, ensure that your database schema is updated by running the migration commands or dropping and recreating tables during development.
- **NLP Model Downloads:** Make sure that both spaCy and stanza models are downloaded correctly.
- **AI Model Configuration:** Verify that the LM Studio server is correctly set up and reachable at the specified host and port.

Enjoy using the Diary Annotation API!
